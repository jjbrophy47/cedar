Exact Unlearning for GBDT (1 instance at a time)


High-Level Pseudocode (Single Tree):

At node, for each attribute, split pair:
	If left is affected:
		Decrement left sum and count, recompute mean and sum of square loss.
	If right is affected:
       		Decrement right sum and count, recompute mean and sum of square loss.

	Recompute objective.
	If this objective is the best:
		Save this attribute and split.

If attribute is the same as before:
	If split is the same as before:
		The check is done.
		Traverse left or right, depending on which branch is affected.
	Else:
		Split data to the left and right.
		Rebuild the subtree below this node.
Else:
	Split data to the left and right.
	Rebuild the subtree below this node.


Objective:
ssle1 + ssle2
ssle1 = sum_i (y_i - mu1)^2
ssle2 = sum_i (y_i - mu2)^2
mu1 = mean y_value of left indices
mu2 = mean y_value of right indices

Info on splitting for GBDT using least square error as the criterion:

MSE for the mean squared error, which is equal to variance
        reduction as feature selection criterion and minimizes the L2 loss
        using the mean of each terminal node, "friedman_mse", which uses mean
        squared error with Friedman's improvement score for potential splits,
        and "mae" for the mean absolute error, which minimizes the L1 loss
        using the median of each terminal node.

So variance reduction in a regression tree is the same as using MSE in GBDT
to find the optimal splits.


Time Complexity:

When updating a node, even storing the metadata to make checking a single
attribute, value pair faster, the runtime to delete a single instance seems
to be directly correlated to the number of total attribute, value pairs
that need to be checked for a given node.


Difference between checking and rebuilding:

Checking requires only recomputing one half of the objective
for each node. Checking also only requires one path through the tree, the
affected branches. Also, metadata is stored to making checking each
attribute, value pair quicker.

Rebuilding needs to separate the instances
based on feature values on a sorted array, and then compute the full objective
for each side of a node. It needs to do this for all paths through the tree.


Algorithmic Analysis (needs to be updated):

Checking requires the decrement of the sum and count, and a division to compute the mean.
Then, the sum of square loss needs to be recomputed, and one addition to recompute the
objective. This only needs to be done to either the left or right side. This results
in O(1)+O(1)+O(1)+O(n)+O(1) = O(n)

Rebuilding needs to recompute the mean, and count, both are O(n) operations. Then, the
sum of square loss needs to be recomputed, another O(n), and the objective. This also
needs to be done for both left and right, resulting in O(n)+O(n)+O(1) times 2 = 2*2*O(n)